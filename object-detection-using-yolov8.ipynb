{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wk25cOQb59F0","outputId":"43489dcb-52a3-4115-d13c-b39898e60227"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Mounted at /content/drive\n"}]},{"cell_type":"code","source":"ROOT_DIR = '/content/drive/My Drive/Computer_vision/Obj_detection1'","metadata":{"id":"2axCiYXG6FhK"},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vn5dqVFv6Ran","outputId":"c6cccb73-9a47-49f7-c256-e90257e2ba90"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting ultralytics\n\n  Downloading ultralytics-8.3.21-py3-none-any.whl.metadata (34 kB)\n\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n\n  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n\nDownloading ultralytics-8.3.21-py3-none-any.whl (877 kB)\n\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m877.1/877.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n\nInstalling collected packages: ultralytics-thop, ultralytics\n\nSuccessfully installed ultralytics-8.3.21 ultralytics-thop-2.0.9\n"}]},{"cell_type":"code","source":"import os\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolov8n.yaml')\nresults = model.train(data=os.path.join(ROOT_DIR, 'config.yaml'), epochs=10)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"W_iTj4gE6UYy","outputId":"54e294f2-9495-483f-95a9-8b64ffbb7107"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \n\nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\nUltralytics 8.3.21 ğŸš€ Python-3.10.12 torch-2.5.0+cu121 CPU (Intel Xeon 2.20GHz)\n\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/drive/My Drive/Computer_vision/Obj_detection1/config.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"},{"output_type":"stream","name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 15.4MB/s]\n"},{"output_type":"stream","name":"stdout","text":"Overriding model.yaml nc=80 with nc=1\n\n\n\n                   from  n    params  module                                       arguments                     \n\n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n\n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n\n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n\n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n\n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n\n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n\n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n\n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n\n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n\n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n\n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n\n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n\n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n\n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n\n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n\n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n\n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n\n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n\n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n\n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n\n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n\n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n\n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n\nYOLOv8n summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n\n\n\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n"},{"output_type":"stream","name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\nwandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"},{"name":"stdout","output_type":"stream","text":" Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"output_type":"stream","name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241024_143235-q5z0s7tf</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics/runs/q5z0s7tf' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics' target=\"_blank\">https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics/runs/q5z0s7tf' target=\"_blank\">https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics/runs/q5z0s7tf</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":"Freezing layer 'model.22.dfl.conv.weight'\n"},{"output_type":"stream","name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/Computer_vision/Obj_detection1/labels/train... 101 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:47<00:00,  2.14it/s]"},{"output_type":"stream","name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/My Drive/Computer_vision/Obj_detection1/labels/train.cache\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"},{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.19 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n\n  check_for_updates()\n\n\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/Computer_vision/Obj_detection1/labels/val... 54 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:50<00:00,  1.08it/s]"},{"output_type":"stream","name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/My Drive/Computer_vision/Obj_detection1/labels/val.cache\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n\nImage sizes 640 train, 640 val\n\nUsing 0 dataloader workers\n\nLogging results to \u001b[1mruns/detect/train\u001b[0m\n\nStarting training for 10 epochs...\n\nClosing dataloader mosaic\n\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       1/10         0G      2.967      3.643      4.257          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [02:01<00:00, 17.31s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:23<00:00, 11.79s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00602      0.639      0.027    0.00766\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       2/10         0G      3.093      3.541      4.244         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:44<00:00, 14.94s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.38s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00599      0.632     0.0348    0.00956\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       3/10         0G      3.022       3.47      4.159          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:43<00:00, 14.79s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.49s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00598      0.632     0.0241    0.00663\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       4/10         0G      2.963      3.425      4.158         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:42<00:00, 14.64s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:20<00:00, 10.23s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00595      0.632     0.0219    0.00682\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       5/10         0G      2.974      3.337      4.108         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:40<00:00, 14.41s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.55s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00589      0.639     0.0333    0.00949\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       6/10         0G      2.888      3.334      4.052         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:46<00:00, 15.27s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.79s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00581      0.632     0.0341    0.00967\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       7/10         0G      2.875      3.397      3.965          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:42<00:00, 14.71s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.66s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00587      0.639     0.0282     0.0086\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       8/10         0G      2.797      3.281      3.913         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:40<00:00, 14.34s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.48s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00587      0.639     0.0281    0.00853\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"       9/10         0G      2.796      3.215      3.868         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:40<00:00, 14.34s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.34s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00584      0.639     0.0276    0.00862\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"},{"output_type":"stream","name":"stderr","text":"      10/10         0G      2.828      3.263       3.88         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:42<00:00, 14.64s/it]\n\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.25s/it]"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00604      0.662     0.0288    0.00928\n"},{"output_type":"stream","name":"stderr","text":"\n"},{"output_type":"stream","name":"stdout","text":"\n\n10 epochs completed in 0.346 hours.\n\nOptimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n\nOptimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n\n\n\nValidating runs/detect/train/weights/best.pt...\n\nWARNING âš ï¸ validating an untrained model YAML will result in 0 mAP.\n\nUltralytics 8.3.21 ğŸš€ Python-3.10.12 torch-2.5.0+cu121 CPU (Intel Xeon 2.20GHz)\n\nYOLOv8n summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"},{"output_type":"stream","name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.26s/it]\n"},{"output_type":"stream","name":"stdout","text":"                   all         54        133    0.00581      0.632     0.0339    0.00973\n\nSpeed: 2.6ms preprocess, 254.1ms inference, 0.0ms loss, 3.0ms postprocess per image\n\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–†â–„â–‚</td></tr><tr><td>lr/pg1</td><td>â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–†â–„â–‚</td></tr><tr><td>lr/pg2</td><td>â–â–„â–†â–‡â–ˆâ–ˆâ–‡â–†â–„â–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–„â–ˆâ–‚â–â–‡â–ˆâ–„â–„â–„â–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–ƒâ–ˆâ–â–â–‡â–ˆâ–…â–…â–…â–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–ˆâ–‡â–‡â–†â–„â–â–ƒâ–ƒâ–‚â–</td></tr><tr><td>metrics/recall(B)</td><td>â–ˆâ–â–â–â–ˆâ–â–ˆâ–ˆâ–ˆâ–</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>train/box_loss</td><td>â–…â–ˆâ–†â–…â–…â–ƒâ–ƒâ–â–â–‚</td></tr><tr><td>train/cls_loss</td><td>â–ˆâ–†â–…â–„â–ƒâ–ƒâ–„â–‚â–â–‚</td></tr><tr><td>train/dfl_loss</td><td>â–ˆâ–ˆâ–†â–†â–…â–„â–ƒâ–‚â–â–</td></tr><tr><td>val/box_loss</td><td>â–ˆâ–ˆâ–‡â–†â–ƒâ–‚â–‚â–ƒâ–‚â–</td></tr><tr><td>val/cls_loss</td><td>â–ˆâ–ˆâ–ˆâ–†â–„â–ƒâ–‚â–â–ƒâ–</td></tr><tr><td>val/dfl_loss</td><td>â–„â–„â–„â–ƒâ–â–â–ƒâ–…â–ˆâ–‡</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00015</td></tr><tr><td>lr/pg1</td><td>0.00015</td></tr><tr><td>lr/pg2</td><td>0.00015</td></tr><tr><td>metrics/mAP50(B)</td><td>0.03393</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.00973</td></tr><tr><td>metrics/precision(B)</td><td>0.00581</td></tr><tr><td>metrics/recall(B)</td><td>0.63158</td></tr><tr><td>model/GFLOPs</td><td>8.194</td></tr><tr><td>model/parameters</td><td>3011043</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>264.817</td></tr><tr><td>train/box_loss</td><td>2.8282</td></tr><tr><td>train/cls_loss</td><td>3.26348</td></tr><tr><td>train/dfl_loss</td><td>3.87993</td></tr><tr><td>val/box_loss</td><td>3.16152</td></tr><tr><td>val/cls_loss</td><td>3.4612</td></tr><tr><td>val/dfl_loss</td><td>4.16615</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">train</strong> at: <a href='https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics/runs/q5z0s7tf' target=\"_blank\">https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics/runs/q5z0s7tf</a><br/> View project at: <a href='https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics' target=\"_blank\">https://wandb.ai/jaivarshan11-kpr-institute-of-engineering-and-technology/Ultralytics</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 19 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20241024_143235-q5z0s7tf/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":"!scp -r /content/runs '/content/drive/MyDrive/Computer_vision/Obj_detection1'","metadata":{"id":"_MYlWGkS7pXr"},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"LJMkodZXHuz0"},"execution_count":null,"outputs":[]}]}